研究领域：三维重建
-----  
题目：Toward Cooperative 3D Object Reconstruction with Multi-agent
-----  
原文链接：https://github.com/ZYJ-Group/darren_pty/tree/main/darren_pty/0-paper  
-----  




### 一、简介：
  - 创新点：先前的研究工作是单个相机连续拍摄情况下的物体重建问题，作者使用3个相机的协作方式重建特定目标
    - 1、仅需很少的图像即可实现卓越的3D重建性能
    - 2、一种单视点对象重建方法，该方法使每个代理都能在目标对象上达成共识，克服环境干扰的挑战，并在每个视点处恢复目标对象的局部3D模型
    - 3、开发了一种基于标记的鲁棒点云级联算法，该算法利用代理之间的合作关系在广泛变化的视点之间建立稳定的连接，然后以较低的计算成本将所有本地信息快速集成在一起
  - 步骤：
     - 1、首先，从不同相机同时检测目标，并将各自视角的观察图像上传到云服务器，恢复局部3D模型；
     - 2、然后，对齐重建空间中不同相机的固有特征，从而生成的姿势估计参数来实现所有局部3D模型的串联；
     - 3、最后，使用估计的参数对所有局部模型进行积分；

![](https://img-blog.csdnimg.cn/fdba376c5a6141d79ccc87955eb59a3a.png)


### 二、具体步骤：
首先，```单视点对象重建```方法使每个代理从2D图像中重建局部3D对象 (目标对象的部分3D信息)。

接下来，```多视点串联```方法通过在重建空间中对齐协作代理的内在特征来估计相对姿势，从而将所有本地信息集成到一个完整的3D模型中。

#### 2.1单视点对象重建 (§ ii-b)
（0）第k个相机下产生的原始图像对，通过它们恢复场景3D坐标Sk  (即场景点云)。


（1）去除径向和切向失真，然后通过Bouguet算法对去失真的图像进行立体校正 [15]。校正后的左右图像 {imlk，imrk} 是行对齐的，即同一对象点在两个图像中都位于同一行。


（2）我们需要为左图像中的像素在右图像中找到相应的点，并计算视差。

这项工作不是传统的立体匹配方法，而是基于cf-net端到端获得更高质量的视差图 [29]。以校正后的立体图像 {imlk，imrk} 作为输入，网络以相同的分辨率输出视差图 {dplk，dprk}。


（3）选择左右视图中的一个作为基准来计算3D坐标

以左视图为例，对于iml的任意像素点 (u，v)，对应对象点的3D坐标 [X Y Z]T可以通过以下公式计算。

![](https://img-blog.csdnimg.cn/a33c416859d04d9fb0befa5a97bd7c0b.png)

其中，d表示视差图dplk的相应位置的值。cx，c'x分别表示在相应的图像平面中左右相机的光学中心的横坐标。cy是左摄像机在其像平面上的光学中心的纵坐标。双目相机的基线长度用B表示，f为焦距。


（4）为了进一步获得目标对象的平滑局部点云，我们依次进行目标分割和过滤。

首先使用YOLACT [1] 从场景点云Sk中大致提取属于目标对象的点云Ek ∈ rne × 3。

使用左视图作为网络的输入。网络将对输入图像进行像素级的对象检测，并为每个检测到的对象生成一个类标签和相应的掩码，利用这些信息从场景点云中检索和提取指定对象的点云。


（5）掩模中可能存在的噪声以及重建过程本身的噪声，我们最终使用统计滤波器对提取的点云Ek进行平滑处理，以获得Pk ∈ rno × 3。滤波器的阈值h由等式定义2.滤波器将顺序计算Ek中第i个3D点与其w (自定义) 最近邻居之间的平均距离Oi。如果Oi大于阈值，则将3D点标记为异常值并删除，否则保留。

在此阶段，可以独立处理每个立体对图像，以获得```相应视点下的目标局部点云Pk```。


#### 2.2多视点串联 (§ ii-c)
我们将描述如何在协作对象重建任务下估计代理的相对姿势。通过估计的参数，我们可以轻松地将所有参与的代理关联起来，并集成所有本地3D点云以恢复完整的目标对象。

（1）手工标记

协作相机之间的相互可见性，手工制作的标记预先添加到每个参与的摄像机中，以便它可以与目标对象一起出现在其他摄像机的视图中，如图所示。

![](https://img-blog.csdnimg.cn/1264c33d1d7f47b7b333f85e5651aad9.png)

（2）标记部分进行点云匹配

- 为了进行基于标记的点云匹配，我们首先根据YOLACT生成的mask```从原始图像中裁剪完整的标记```；
- 在获得所有视点下的标记图像后，将同一标记分组，每种标记代表YOLACT的一类；
- 然后，使用A-SIFT```从标记的图像中提取关键点 (特征) 并匹配这些关键点```
- 确定了标记图像上关键点的坐标和匹配关系后，我们进一步根据标记的裁剪位置确定它们在原始图像上的对应坐标。
- 然后，可以在场景点云中提取与关键点对应的点云 (即特征点云)。我们按相应标记的类别对它们进行分组。
- 最后，从这些特征点云组构建了一组匹配的点云
- 通过同步对齐所有特征点云组来估计代理的相对姿态


#### 2.3 重建效果
![](https://github.com/ZYJ-Group/darren_pty/blob/main/darren_pty/pic(Ninth%20week)/20.png)
