**1.** 本周采用了原本的模型框架 + Mamba2 去测试了一下结果(0db，3200个训练，800个验证)

<img src="./images/%7B2E472356-A2CF-491B-9428-68D24276EBA9%7D.png" alt="{2E472356-A2CF-491B-9428-68D24276EBA9}" style="zoom:50%;" />

![f07688ae3e61606ee2d396abe3e669d](./images/f07688ae3e61606ee2d396abe3e669d.png)

郑烨的结果

**ACC: 0.9676, IOU: 0.6362, SIM: 0.8238**

在训练输入少一半的情况下，效果比郑烨的在20db（实际15左右）的情况下要好一点。

目前的参数量和复杂度：

![e647788750769b36385c07759f5f0f7](./images/e647788750769b36385c07759f5f0f7.png)

![eff5d82714e900490a9f0d17f87fa83](./images/eff5d82714e900490a9f0d17f87fa83.png)

参数量和复杂度为郑烨的百分之43。

然后我又找了一个根据近似微分方程的方法来去改进。发现最后模型复杂度太高，训练速度过慢就放弃了。

1.我还想在模型上加上一些其他的东西，下周继续改一下模型,下周想试一下能不能在mamba2的框架上，用上能量信息，去做到一个类似于交叉注意力的功能，这块目前没人做。

2.

![3730154a5731ca17529dda9cb6c006a](./images/3730154a5731ca17529dda9cb6c006a.jpg)

这个周期脉冲序列状态转移图，和mamba的思路很相似，因为mamba实现了类似的状态空间模型计算。

<img src="./images/0a021e01e2b7f9ec895b1d2d93af9d0.jpg" alt="0a021e01e2b7f9ec895b1d2d93af9d0" style="zoom:50%;" />

这种能够捕获时间段内的长距离依赖关系，适应不同的PRI间的调制类型。



感觉这个点是不是可以写一下，目前深度学习的论文里，没有通过状态空间模型来写的。





**2.**复习深度学习，准备深度学习的考试和大作业。

<img src="./images/%7B9C8951C1-F3D8-4F90-A9E7-609D84296D13%7D-1746347177928-6.png" alt="{9C8951C1-F3D8-4F90-A9E7-609D84296D13}" style="zoom:50%;" />

<img src="./images/%7BC1C62E5A-A0C7-4D97-B5D9-8357074457B7%7D-1746347192483-9.png" alt="{C1C62E5A-A0C7-4D97-B5D9-8357074457B7}" style="zoom:50%;" />